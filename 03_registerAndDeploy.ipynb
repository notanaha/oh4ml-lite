{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime, sys\n",
    "from azureml.core import Workspace, Environment, Datastore\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AksWebservice, AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': 'arima-mlops-remote-v3_1650758172_65c70524',\n",
       " 'model_name': 'arima-model-v3',\n",
       " 'RMSE': 461.5953678665711,\n",
       " 'R2': 0.10350758763675871}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"./scripts/metric.json\") as f:\n",
    "    metric = json.load(f)\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model arima-model-v3\n",
      "arima-model-v3 arima model 7\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('./', 'models')\n",
    "model = Model.register(model_path = model_path, # this points to a local file\n",
    "                       model_name = metric['model_name'], # this is the name the model is registered as\n",
    "                       tags = metric,\n",
    "                       description = \"arima model\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import os, json\n",
    "import numpy\n",
    "from azureml.core.model import Model\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    import joblib\n",
    "\n",
    "    # load the model from file into a global object\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'models/arima_model.pkl')\n",
    "    # model_path = Model.get_model_path(model_name=\"arima-model\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = numpy.array(data)\n",
    "        result=model.forecast(steps=data[0])[0]\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-04-24 00:02:45+00:00 Creating Container Registry if not exists.\n",
      "2022-04-24 00:02:45+00:00 Registering the environment.\n",
      "2022-04-24 00:02:46+00:00 Use the existing image.\n",
      "2022-04-24 00:02:46+00:00 Generating deployment configuration.\n",
      "2022-04-24 00:02:47+00:00 Submitting deployment to compute.\n",
      "2022-04-24 00:02:53+00:00 Checking the status of deployment arima-model-v3..\n",
      "2022-04-24 00:04:45+00:00 Checking the status of inference endpoint arima-model-v3.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "myenv = Environment.from_conda_specification(name=\"arima-env\", file_path=\"./arima-env.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=3, \n",
    "                                               tags={'name': metric['model_name'], 'framework': 'statsmodels'},\n",
    "                                               description='arima inference')\n",
    "\n",
    "service = Model.deploy(workspace=workspace,\n",
    "                           name=metric['model_name'], \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig, overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-24T00:04:24,527867800+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-04-24T00:04:24,530129300+00:00 - rsyslog/run \n",
      "2022-04-24T00:04:24,543682200+00:00 - iot-server/run \n",
      "2022-04-24T00:04:24,585013200+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-04-24T00:04:24,973842400+00:00 - iot-server/finish 1 0\n",
      "2022-04-24T00:04:24,976693600+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (73)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 100\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-04-24 00:04:30,045 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-04-24 00:04:30,046 | root | INFO | Starting up request id generator\n",
      "2022-04-24 00:04:30,046 | root | INFO | Starting up app insight hooks\n",
      "2022-04-24 00:04:30,050 | root | INFO | Invoking user's init function\n",
      "2022-04-24 00:04:30,204 | root | INFO | Users's init has completed successfully\n",
      "2022-04-24 00:04:30,208 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2022-04-24 00:04:30,208 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2022-04-24 00:04:30,211 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2022-04-24 00:04:45,409 | root | INFO | Swagger file not present\n",
      "2022-04-24 00:04:45,409 | root | INFO | 404\n",
      "127.0.0.1 - - [24/Apr/2022:00:04:45 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2022-04-24 00:04:47,257 | root | INFO | Swagger file not present\n",
      "2022-04-24 00:04:47,258 | root | INFO | 404\n",
      "127.0.0.1 - - [24/Apr/2022:00:04:47 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://a021201f-b48a-4cf1-974b-b270ede0dae3.japaneast.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"data\": [3]}'\n"
     ]
    }
   ],
   "source": [
    "step_size=[3]\n",
    "test_sample = json.dumps({\"data\": step_size})\n",
    "test_sample = bytes(test_sample, encoding=\"utf8\")\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [626.5655200695544, 768.0510945310739, 819.0250224534511]}\n"
     ]
    }
   ],
   "source": [
    "prediction = service.run(input_data=test_sample)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
