{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime, sys\n",
    "from azureml.core import Workspace, Environment\n",
    "\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(ws, 'arima_model.pkl')  #, version=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from azureml.core.model import Model\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    import joblib\n",
    "\n",
    "    # load the model from file into a global object\n",
    "    model_path = Model.get_model_path(model_name=\"arima_model.pkl\")\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)[\"data\"]\n",
    "        data = numpy.array(data)\n",
    "        result=model.forecast(steps=data[0])[0]\n",
    "        return json.dumps({\"result\": result.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment.from_conda_specification(name=\"arima-env\", file_path=\"./arima-env.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=3, \n",
    "                                               tags={'name':'arima-inference', 'framework': 'statsmodels'},\n",
    "                                               description='arima inference')\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                           name='arima-inference', \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig, overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size=[3]\n",
    "test_sample = json.dumps({\"data\": step_size})\n",
    "test_sample = bytes(test_sample, encoding=\"utf8\")\n",
    "print(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = service.run(input_data=test_sample)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
